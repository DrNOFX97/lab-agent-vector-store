{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efad6479-7fb1-40c4-8610-8963f8de307f",
   "metadata": {},
   "source": [
    "# Lab | Agent & Vector store\n",
    "\n",
    "**Change the state union dataset and replicate this lab by updating the prompts accordingly.**\n",
    "\n",
    "One such dataset is the [sonnets.txt](https://github.com/martin-gorner/tensorflow-rnn-shakespeare/blob/master/shakespeare/sonnets.txt) dataset or any other data of your choice from the same git."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b24990",
   "metadata": {},
   "source": [
    "# Combine agents and vector stores\n",
    "\n",
    "This notebook covers how to combine agents and vector stores. The use case for this is that you've ingested your data into a vector store and want to interact with it in an agentic manner.\n",
    "\n",
    "The recommended method for doing so is to create a `RetrievalQA` and then use that as a tool in the overall agent. Let's take a look at doing this below. You can do this with multiple different vector DBs, and use the agent as a way to route between them. There are two different ways of doing this - you can either let the agent use the vector stores as normal tools, or you can set `return_direct=True` to really just use the agent as a router."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b22020a",
   "metadata": {},
   "source": [
    "## Create the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12df91e0-7322-43c2-96cd-0159d017a1e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install langchain chromadb openai langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2868cff1-a3ef-426f-b8d7-7fe89047a5b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from pathlib import Path\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAI, OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader, WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain.agents import AgentType, Tool, initialize_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aeff3a2d-b0cc-429f-a34c-4381d71f1a5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# API keys\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14331eec-fd46-42e0-b6e7-adaf21824ef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b7b772b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "relevant_parts = []\n",
    "for p in Path(\".\").absolute().parts:\n",
    "    relevant_parts.append(p)\n",
    "    if relevant_parts[-3:] == [\"langchain\", \"docs\", \"modules\"]:\n",
    "        break\n",
    "doc_path = str(Path(*relevant_parts) / \"Hamlet.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2675861",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1251, which is longer than the specified 1000\n",
      "Created a chunk of size 1743, which is longer than the specified 1000\n",
      "Created a chunk of size 1361, which is longer than the specified 1000\n",
      "Created a chunk of size 1400, which is longer than the specified 1000\n",
      "Created a chunk of size 1511, which is longer than the specified 1000\n",
      "Created a chunk of size 1227, which is longer than the specified 1000\n",
      "Created a chunk of size 1102, which is longer than the specified 1000\n",
      "Created a chunk of size 2077, which is longer than the specified 1000\n",
      "Created a chunk of size 1527, which is longer than the specified 1000\n",
      "Created a chunk of size 1277, which is longer than the specified 1000\n",
      "Created a chunk of size 2481, which is longer than the specified 1000\n",
      "Created a chunk of size 1529, which is longer than the specified 1000\n",
      "Created a chunk of size 1022, which is longer than the specified 1000\n",
      "Created a chunk of size 1441, which is longer than the specified 1000\n",
      "Created a chunk of size 1327, which is longer than the specified 1000\n",
      "Created a chunk of size 1616, which is longer than the specified 1000\n",
      "Created a chunk of size 1003, which is longer than the specified 1000\n",
      "Created a chunk of size 1568, which is longer than the specified 1000\n",
      "Created a chunk of size 1509, which is longer than the specified 1000\n",
      "Created a chunk of size 1070, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "loader = TextLoader(doc_path)\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "docsearch = Chroma.from_documents(texts, embeddings, collection_name=\"hamlet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc5403d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the RetrievalQA system for Hamlet\n",
    "hamlet_qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1431cded",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "915d3ff3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\"https://apple.github.io/coremltools/docs-guides/source/overview-coremltools.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96a2edf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs = loader.load()\n",
    "coreml_texts = text_splitter.split_documents(docs)\n",
    "coreml_db = Chroma.from_documents(coreml_texts, embeddings, collection_name=\"coreml\")\n",
    "coreml_qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm, chain_type=\"stuff\", retriever=coreml_db.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a6c031",
   "metadata": {},
   "source": [
    "## Create the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb142786",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import things that are needed generically\n",
    "from langchain.agents import AgentType, Tool, initialize_agent\n",
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "850bc4e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define tools for the agent\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Hamlet QA System\",\n",
    "        func=hamlet_qa.run,\n",
    "        description=\"Useful for answering questions about the text of Hamlet.\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"CoreML QA System\",\n",
    "        func=coreml_qa.run,\n",
    "        description=\"Useful for answering questions about the CoreML tools documentation.\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc47f230",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# Initialize the agent\n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10ca2db8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use the Hamlet QA System to find the main theme of the play.\n",
      "Action: Hamlet QA System\n",
      "Action Input: \"What is the main theme of Hamlet?\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m The main theme of Hamlet is the struggle with mortality and the question of whether it is better to live and suffer or to die and end all pain.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The main theme of Hamlet is the struggle with mortality and the question of whether it is better to live and suffer or to die and end all pain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the main theme of Hamlet?',\n",
       " 'output': 'The main theme of Hamlet is the struggle with mortality and the question of whether it is better to live and suffer or to die and end all pain.'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\n",
    "    \"What is the main theme of Hamlet?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e91b811",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use the CoreML QA System to answer this question.\n",
      "Action: CoreML QA System\n",
      "Action Input: \"What is CoreML and what are its main features?\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m CoreML is a machine learning framework developed by Apple for use in iOS, macOS, watchOS, and tvOS applications. It allows developers to integrate trained machine learning models into their apps, making it easier to incorporate features such as image recognition, natural language processing, and more. Some of its main features include support for various libraries and frameworks, a unified conversion process, and the ability to convert models to both ML programs and neural networks.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: CoreML is a machine learning framework developed by Apple for use in iOS, macOS, watchOS, and tvOS applications. Some of its main features include support for various libraries and frameworks, a unified conversion process, and the ability to convert models to both ML programs and neural networks.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is CoreML and what are its main features?',\n",
       " 'output': 'CoreML is a machine learning framework developed by Apple for use in iOS, macOS, watchOS, and tvOS applications. Some of its main features include support for various libraries and frameworks, a unified conversion process, and the ability to convert models to both ML programs and neural networks.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"What is CoreML and what are its main features?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787a9b5e",
   "metadata": {},
   "source": [
    "## Use the Agent solely as a router"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9161ba91",
   "metadata": {},
   "source": [
    "You can also set `return_direct=True` if you intend to use the agent as a router and just want to directly return the result of the RetrievalQAChain.\n",
    "\n",
    "Notice that in the above examples the agent did some extra work after querying the RetrievalQAChain. You can avoid that and just return the result directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f59b377e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define tools for the agent\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Hamlet QA System\",\n",
    "        func=hamlet_qa.run,\n",
    "        description=\"Useful for answering questions about the text of Hamlet.\",\n",
    "        return_direct=True\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"CoreML QA System\",\n",
    "        func=coreml_qa.run,\n",
    "        description=\"Useful for answering questions about the CoreML tools documentation.\",\n",
    "        return_direct=True\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8615707a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36e718a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m This is a famous quote from Hamlet, so I should use the Hamlet QA System.\n",
      "Action: Hamlet QA System\n",
      "Action Input: \"To be or not to be?\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m The question is whether it is better to live and suffer through life's challenges or to end one's life and potentially escape those challenges.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'To be or not to be?',\n",
       " 'output': \" The question is whether it is better to live and suffer through life's challenges or to end one's life and potentially escape those challenges.\"}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\n",
    "    \"To be or not to be?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edfd0a1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use the CoreML QA System to find information about the Mac M1.\n",
      "Action: CoreML QA System\n",
      "Action Input: \"How does it accelerate my Mac M1?\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m Core ML optimizes on-device performance by leveraging the CPU, GPU, and Neural Engine (NE) while minimizing its memory footprint and power consumption. This allows for faster and more efficient processing of machine learning models on the Mac M1.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'How does it acceralate my Mac M1?',\n",
       " 'output': ' Core ML optimizes on-device performance by leveraging the CPU, GPU, and Neural Engine (NE) while minimizing its memory footprint and power consumption. This allows for faster and more efficient processing of machine learning models on the Mac M1.'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"How does it acceralate my Mac M1?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a0cbbe",
   "metadata": {},
   "source": [
    "## Multi-Hop vector store reasoning\n",
    "\n",
    "Because vector stores are easily usable as tools in agents, it is easy to use answer multi-hop questions that depend on vector stores using the existing agent framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d397a233",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Hamlet QA System\",\n",
    "        func=hamlet_qa.run,\n",
    "        description=\"Useful for answering questions about the text of Hamlet.\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"CoreML QA System\",\n",
    "        func=coreml_qa.run,\n",
    "        description=\"Useful for answering questions about the CoreML tools documentation.\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06157240",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Construct the agent. We will use the default agent type here.\n",
    "# See documentation for a full list of options.\n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b492b520",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use the Hamlet QA System to find a summary of the story.\n",
      "Action: Hamlet QA System\n",
      "Action Input: \"summary of Hamlet\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m Hamlet is a play by William Shakespeare that follows the story of Prince Hamlet, who is seeking revenge for his father's murder. The play is set in Denmark and includes a cast of characters such as King Claudius, Hamlet's uncle and the current king, Polonius, the lord chamberlain, and Horatio, Hamlet's friend. The play also features the ghost of Hamlet's father, who reveals that he was murdered by Claudius. Hamlet struggles with his desire for revenge and his own moral code, leading to a series of tragic events. The play also explores themes of madness, betrayal, and family relationships.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This is a good summary, but I should also check the CoreML QA System for any additional information.\n",
      "Action: CoreML QA System\n",
      "Action Input: \"Hamlet summary\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m I'm sorry, I don't know the answer to that question. The context provided does not mention anything about Hamlet or its summary.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m It seems like the CoreML QA System is not the best tool for this question. I should stick with the Hamlet QA System.\n",
      "Final Answer: Hamlet is a play by William Shakespeare that follows the story of Prince Hamlet, who is seeking revenge for his father's murder. The play is set in Denmark and includes a cast of characters such as King Claudius, Hamlet's uncle and the current king, Polonius, the lord chamberlain, and Horatio, Hamlet's friend. The play also features the ghost of Hamlet's father, who reveals that he was murdered by Claudius. Hamlet struggles with his desire for revenge and his own moral code, leading to a series of tragic events. The play also explores themes of madness, betrayal, and family relationships.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Short story about Hamlet?',\n",
       " 'output': \"Hamlet is a play by William Shakespeare that follows the story of Prince Hamlet, who is seeking revenge for his father's murder. The play is set in Denmark and includes a cast of characters such as King Claudius, Hamlet's uncle and the current king, Polonius, the lord chamberlain, and Horatio, Hamlet's friend. The play also features the ghost of Hamlet's father, who reveals that he was murdered by Claudius. Hamlet struggles with his desire for revenge and his own moral code, leading to a series of tragic events. The play also explores themes of madness, betrayal, and family relationships.\"}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\n",
    "    \"Short story about Hamlet?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07962ca3-5247-4023-b771-caebb157b586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use the Hamlet QA System to find the answer\n",
      "Action: Hamlet QA System\n",
      "Action Input: \"What happens at the end of Hamlet?\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m At the end of Hamlet, Hamlet's mother, Queen Gertrude, reveals that Hamlet has killed Polonius in a fit of madness. This leads to a chain of events that ultimately results in the deaths of several characters, including Hamlet himself.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This is a good summary, but I should also check the CoreML QA System for any additional information.\n",
      "Action: CoreML QA System\n",
      "Action Input: \"What are the main events that lead to the end of the play?\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m I don't know, as this context does not mention a play or any events leading to its end.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should try rephrasing my question to be more specific.\n",
      "Action: CoreML QA System\n",
      "Action Input: \"What are the main events that lead to the end of Hamlet?\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m I don't know, as this context does not mention anything about Hamlet or its events.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should try using the Hamlet QA System again, but with a more specific question.\n",
      "Action: Hamlet QA System\n",
      "Action Input: \"What are the main events that lead to the end of Hamlet?\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m The main events that lead to the end of Hamlet include the death of Hamlet's father and his subsequent encounter with his father's ghost, which reveals that his uncle Claudius is responsible for his father's death. Hamlet then struggles with his desire for revenge and his own moral code, leading to his feigned madness and the deaths of Polonius, Ophelia, and Laertes. This ultimately leads to a duel between Hamlet and Laertes, where both are fatally wounded. In the end, Hamlet fulfills his revenge by killing Claudius and dies himself, leaving the throne to Fortinbras.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This is a comprehensive summary of the end of the play.\n",
      "Final Answer: The end of Hamlet is marked by a series of tragic events, including the deaths of several characters and Hamlet's fulfillment of his revenge against his uncle Claudius.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'short summary of the end of the play',\n",
       " 'output': \"The end of Hamlet is marked by a series of tragic events, including the deaths of several characters and Hamlet's fulfillment of his revenge against his uncle Claudius.\"}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\n",
    "    \"short summary of the end of the play\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
